---
tags:
  - topic/cloud
  - type/practice
Date: 2026-01-08
aliases:
  - pv
  - pvc
  - storageclass
  - volume
---
## Volume
<img width="1179" height="325" alt="Pasted image 20260113215234" src="https://github.com/user-attachments/assets/3be5ae83-25e5-475b-8008-70e6463f4eaf" />

[Kubernetes - Volumes](https://kubernetes.io/docs/concepts/storage/volumes/)
- provide a way for containers in a pod to access and share data via the filesystem.
- Why volumes are important
	- Data Persistene
	- Shared Storage
<img width="1143" height="514" alt="Pasted image 20260113215306" src="https://github.com/user-attachments/assets/7bee1b62-ac18-499a-b272-c9bdbcd177af" />
<img width="1169" height="542" alt="Pasted image 20260113215326" src="https://github.com/user-attachments/assets/308b665f-f122-468d-900a-e3a4a150725c" />

- 사용자가 필요한 스토리지의 크기와 접근 모드(ReadWriteOnce, ReadOnlyMany, ReadWriteMany)를 정의하고, 이를 기반으로 클러스터 내의 적절한 PV에 바인딩
### 1. Volume: `emptyDir`
#### 1-1. Pod 생성
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: jde-pod-volume
  namespace: default
spec:
  volumes:
    - name: secloudit-log-volume
      emptyDir: {}                 # Pod가 생성될 때 생성되는 임시 볼륨 정의
  containers:
    - name: secloudit-log-writer
      image: busybox
      command: ["/bin/sh", "-c"]
      args:
        - while true; do
            echo "$(date)" >> /var/log/secloudit.log;
            sleep 5;
          done
      volumeMounts:
        - name: secloudit-log-volume
          mountPath: /var/log
    - name: secloudit-log-reader
      image: busybox
      command: ["/bin/sh", "-c"]
      args:
        - tail -f /var/log/secloudit.log
      volumeMounts:
        - name: secloudit-log-volume
          mountPath: /var/log
```
```sh
# PV를 정의한 Pod 생성
$ kubectl apply -f volume.yaml

# Pod 목록 조회
$ kubectl get pods
```
<img width="2013" height="842" alt="Pasted image 20260108104443" src="https://github.com/user-attachments/assets/2b47844e-3ab3-40ba-8186-4e202e0bcd33" />

- 로그를 Pod 내의 컨테이너에 Volume을 mount하여 쌓음
#### 1-2. Pod 접속하여 로그 조회
```sh
# Pod 접속하여 shell 프로세스 실행
$ kubectl exec -it jde-pod-volume -- /bin/sh
```
<img width="1665" height="961" alt="Pasted image 20260108104620" src="https://github.com/user-attachments/assets/f0e77171-bedd-4c99-8d98-faca927cac46" />

- 설정한 `mountPath: /var/log`에 로그가 쌓이는 것을 확인할 수 있다.
### 2. Volume: `hostPath`
#### 2-1. Pod 생성
```yaml
# volume2.yaml
apiVersion: v1
kind: Pod
metadata:
  name: jde-pod-volume2
  namespace: default
spec:
  containers:
  - name: secloudit-log-writer    
    image: busybox
    command: ["sh", "-c"]
    args:
    - while true; do
      echo "$(date)" >> /var/log/secloudit.log;
      sleep 10;
      done
    volumeMounts:      # 컨테이너 내부에 volume을 마운트하는 설정
    - name: secloudit-log-volume   # volume 지정 (name 동일해야 함)
      mountPath: /var/log          # 컨테이너 내부에서 volume을 사용할 위치
  volumes:
  - name: secloudit-log-volume
    hostPath:
      path: /var/log/secloudit-logs   # Pod가 스케줄된 Worker Node의 local fs 경로
      type: DirectoryOrCreate         # 디렉토리가 없으면 자동 생성
```
- `hostPath`: 노드에 강하게 결합되어 Pod 재스케줄 시 로그 사라질 수 있음
```sh
# Pod 생성
$ kubectl apply -f volume2.yaml

# Pod 조회 (wide 옵션으로 조회하여 스케줄된 클러스터 확인)
$ kubectl get pods -o wide 
```
#### 2-2. 로그 조회: Worker Node 접속 or Pod 접속
<img width="2433" height="264" alt="Pasted image 20260108105019" src="https://github.com/user-attachments/assets/a7c1d5a2-7957-48c4-8f9d-596f20b8d763" />

- `jde-pod-volume2`는 `jde-cluster4`에 스케줄되었으므로 
- `jde-cluster4` 접속
<img width="2051" height="1294" alt="Pasted image 20260108105304" src="https://github.com/user-attachments/assets/e034050e-a3b5-4e46-84df-2d139efdb4c6" />

- `ubuntu@jde-cluster4` 이름으로 접속하기 위해 `/etc/hosts`에  Private IP와 hostname 추가
<img width="674" height="285" alt="Pasted image 20260113224210" src="https://github.com/user-attachments/assets/4e490e90-5903-4624-94a0-c65a3e07a8ae" />

- `jde-cluster4:/var/log/secloudit-logs`와 
- `jde-pod-volume2`에 접속하여 `/var/log`로 확인한 로그 결과는 동일하다.
- `hostPath` 필드를 지정하여, 컨테이너 내부(`/var/log`)에 생성된 로그가 Worker Node의 `/var/log/secloudit-logs` 디렉토리에 동일하게 저장되었음을 확인할 수 있다.
<img width="2378" height="1347" alt="Pasted image 20260108105428" src="https://github.com/user-attachments/assets/3157d70e-5ff6-4ca6-a0f6-faedeef4e6e5" />

#### 2-3. Yaml: Pod가 스케줄링될 Worker Node(클러스터) 지정
```yaml
# volume2.yaml
apiVersion: v1
kind: Pod
metadata:
  name: jde-pod-volume2
  namespace: default
spec:
  containers:
  - name: secloudit-log-writer
    image: busybox
    command: ["sh", "-c"]
    args:
    - while true; do
      echo "$(date)" >> /var/log/secloudit.log;
      sleep 10;
      done
    volumeMounts:
    - name: secloudit-log-volume
      mountPath: /var/log
  volumes:
  - name: secloudit-log-volume
    hostPath:
      path: /var/log/secloudit-logs
      type: DirectoryOrCreate
  nodeSelector:
    kubernetes.io/hostname: jde-cluster2   # hostname(클러스터) 지정
```
```sh
# Pod 조회 (지정한 클러스터에 생성)
$ kubectl get pods -o wide
```
<img width="2410" height="226" alt="Pasted image 20260108111001" src="https://github.com/user-attachments/assets/59153d9f-7405-41cc-b45c-910306630642" />

#### 2-4. 지정한 클러스터에 접속하여 로그 조회
```sh
# Pod가 스케줄된 Worker Node에 접속
$ ssh ubuntu@jde-cluster2 -i ~/.ssh/id_rsa
```
<img width="2369" height="889" alt="Pasted image 20260108111249" src="https://github.com/user-attachments/assets/129493f4-2532-4056-be53-ca759b972cd8" />

### 3. PersistentVolume: Static Provisioning
- `emptyDir` 및 `hostPath`와 같이 Pod 또는 Node에 종속된 볼륨을 사용하는 경우에는 별도의 storage 관리 객체가 필요하지 않았음
- 하지만 Persistent Volume을 구성하기 위해서는 PV, PVC, Storage를 사용해야 함.
- 특히 `no-provisioner`를 사용하여 정적 PV를 구성하는 경우 
	- PV + PVC + StorageClass 모두 필요
#### 3-1. PV + PVC + StorageClass
```sh
# volume4.yaml

# StorageClass (Static Provisioning 명시)
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: jde-storageclass
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true'
provisioner: kubernetes.io/no-provisioner
reclaimPolicy: Delete
volumeBindingMode: Immediate
---
# PV
apiVersion: v1
kind: PersistentVolume
metadata:
  name: jde-pv
spec:
  storageClassName: jde-storageclass
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany
  nfs:
    path: "/home/share/nfs"
    server: 192.168.1.9
---
# PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: jde-pvc
spec:
  storageClassName: jde-storageclass
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
```
```sh
# StorageClass, PV, PVC 생성
$ kubectl apply -f volume4.yaml

# 조회
$ kubectl get storageclass,pv,pvc
```
<img width="2437" height="1206" alt="Pasted image 20260108112616" src="https://github.com/user-attachments/assets/42eed5bb-3024-4909-bf7c-035d234f3e3e" />

#### 3-2. Pod 생성
```sh
apiVersion: v1
kind: Pod
metadata:
  name: jde-pod-volume4
  labels:
    name: app
spec:
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'echo "Platform as a service!" > /mnt/secloudit-nfs.log && sleep 3600']
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /mnt
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:       # Pod에 미리 생성된 PV를 마운트할 때 사용하는 필드
        claimName: jde-pvc         # pvc 이름 지정

```
- `persistentVolumeClaim: claimName:`
	- Pod에 영구적으로 데이터를 저장할 수 있는 스토리지 연결
#### 3-3. NFS 접속하여 volume 조회
<img width="2425" height="198" alt="Pasted image 20260108113026" src="https://github.com/user-attachments/assets/52e6d70c-d590-4086-b94f-514060330476" />
<img width="1447" height="266" alt="Pasted image 20260108113219" src="https://github.com/user-attachments/assets/6bcedf49-d515-4c37-a14b-12632901cdd7" />

- `cluster5`는 NFS(스토리지)이므로 `.ssh/ssu-key.pem`으로 접속해야 함.
#### 3-4. Pod 접속하여 volume 조회
- `yaml`파일에서 설정한 `mountPath: /mnt`에 마운트되었음을 확인인
<img width="1644" height="671" alt="Pasted image 20260108113339" src="https://github.com/user-attachments/assets/3fac8030-a07e-420b-97c3-1235e2ef658b" />

### 4. PersistentVolume: Static Provisioning (2)
#### 4-1. 모든 Worker Node에 volume 디렉토리 생성
- 각 Worker Node에 PV를 미리 만들어 두고 수동으로 연결결
```sh
# Worker Node 1 (jde-cluster2)
$ ssh ubuntu@jde-cluster2 ~/.ssh/id_rsa
$ sudo mkdir -p /data/volumes/pv1
$ sudo chmod 777 /data/volumes/pv1

# 나머지 Worker Node에도 동일하게

# Worker Node 2 (jde-cluster3)
$ ssh ubuntu@jde-cluster3 ~/.ssh/id_rsa
$ sudo mkdir -p /data/volumes/pv2
$ sudo chmod 777 /data/volumes/pv2

# Worker Node 3 (jde-cluster4)
$ ssh ubuntu@jde-cluster4 ~/.ssh/id_rsa
$ sudo mkdir -p /data/volumes/pv3
$ sudo chmod 777 /data/volumes/pv3
```
<img width="1190" height="465" alt="Pasted image 20260108115709" src="https://github.com/user-attachments/assets/981e9ae0-9b6b-44a2-8ac4-2cc9763a9681" />
<img width="1556" height="300" alt="Pasted image 20260108115821" src="https://github.com/user-attachments/assets/25e89d8c-4565-4076-abe1-a3e110bb7b65" />
<img width="1370" height="294" alt="Pasted image 20260108115904" src="https://github.com/user-attachments/assets/0e7c78be-eeac-4e1d-8b5b-75fd0868bd93" />

- 실습에서는 `chmod 777`로 권한을 모두 열어두었지만
- 실제로는 `securityContext.fsGroup` 필드로 볼륨 접근에 사용할 GID를 지정한다.
> [Kubernetes Documentation - Configure volume permission and ownership change policy for Pods](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#configure-volume-permission-and-ownership-change-policy-for-pods)
> By default, Kubernetes recursively changes ownership and permissions for the contents of each volume to match the `fsGroup` specified in a Pod's `securityContext` when that volume is mounted.

> [Kubernetes Documentation - DIscussion `fsGroup`](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#discussion)
> `fsGroup`: Volumes that support ownership management are modified **to be owned and writable by the GID** specified in `fsGroup`. See the [Ownership Management design document](https://git.k8s.io/design-proposals-archive/storage/volume-ownership-management.md) for more details.
#### 4-2. Storage Class + PV + PVC
- 공통 StorageClass 정의
- 각 Worker Node의 로컬 `pv` 디렉토리를 매핑하기 위한 PV/PVC 생성
```yaml
# volume3.yaml

# 공통 StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: secloudit-storageclass
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true' # default storage class
provisioner: kubernetes.io/no-provisioner     # static provisioning
reclaimPolicy: Delete  # PVC 삭제 시 데이터와 PV 리소스도 함께 삭제
volumeBindingMode: Immediate    # PVC가 생성되자마자 알맞은 PV를 찾아 즉시 binding
---
# PersistentVolume 1 (jde-cluster2)
apiVersion: v1
kind: PersistentVolume
metadata:
  name: secloudit-pv1
spec:
  storageClassName: secloudit-storageclass   # StorageClass
  persistentVolumeReclaimPolicy: Delete
  capacity:
    storage: 1G
  accessModes:
    - ReadWriteOnce    # 하나의 Node에서만 RW 가능
  local:
    path: /data/volumes/pv1  # local: 네트워크 스토리지가 아닌 로컬 파일 시스템 경로
  nodeAffinity:   # nodeAffinity: 해당 노드에만 존재함을 명시
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname    # hostname 명시
          operator: In
          values:
          - jde-cluster2
---
# PersistentVolume 2 (jde-cluster3)
apiVersion: v1
kind: PersistentVolume
metadata:
  name: secloudit-pv2
spec:
  storageClassName: secloudit-storageclass
  persistentVolumeReclaimPolicy: Delete
  capacity:
    storage: 2G
  accessModes:
    - ReadWriteOnce
  local:
    path: /data/volumes/pv2
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - jde-cluster3
---
# PersistentVolume 3 (jde-cluster4)
apiVersion: v1
kind: PersistentVolume
metadata:
  name: secloudit-pv3
spec:
  storageClassName: secloudit-storageclass
  persistentVolumeReclaimPolicy: Delete
  capacity:
    storage: 3G
  accessModes:
    - ReadWriteOnce
  local:
    path: /data/volumes/pv3
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - jde-cluster4
---
# PersistentVolumeClaim(PVC) 1 
# strageClass: secloudit-storageclass && metadata.name: secoudit-pv1인 PV 바인딩
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: secloudit-pvc1
spec:
  storageClassName: secloudit-storageclass
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1G
---
# PersistentVolumeClaim(PVC) 2
# strageClass: secloudit-storageclass && metadata.name: secoudit-pv2인 PV 바인딩
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: secloudit-pvc2
spec:
  storageClassName: secloudit-storageclass
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2G
---
# PersistentVolumeClaim(PVC) 3
# strageClass: secloudit-storageclass && metadata.name: secoudit-pv3인 PV 바인딩
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: secloudit-pvc3
spec:
  storageClassName: secloudit-storageclass
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3G
```
```sh
# StorageClass, PVC, PV 생성
$ kubectl apply -f volume3.yaml

# pv, pvc 조회
$ kubectl get pv,pvc
# pv, pvc의 STATUS가 Bound임을 확인
```
<img width="2156" height="300" alt="Pasted image 20260108120952" src="https://github.com/user-attachments/assets/5132a2e8-0ea6-4b38-8528-b8c254d966cc" />
<img width="2428" height="1375" alt="Pasted image 20260108121007" src="https://github.com/user-attachments/assets/098e6529-6c8d-4627-af9f-339a3a3699fb" />

#### 4-3. Pod 생성 및 Volume 마운트 (Local Volume & NFS)
```yaml
# pod-volume3.yaml

# Pod 1 
apiVersion: v1
kind: Pod
metadata:
  name: secloudit-pod1
  labels:
    name: app
spec:
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'echo "Platform as a service!" > /mnt/secloudit-1.log && sleep 3600']
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /mnt    # 컨테이너 내부의 /mnt 경로에 volume 마운트
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:
        claimName: secloudit-pvc1 # pvc1 (jde-cluster2의 pv) 사용
---
# Pod 2
apiVersion: v1
kind: Pod
metadata:
  name: secloudit-pod2
  labels:
    name: app
spec:
  containers:
  - name: app
    image: busybox
    command: ["/bin/sh", "-c"]
    args:
      - while true; do
          date >> /mnt/secloudit-2.log;
          sleep 10;
        done
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /mnt
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:
        claimName: secloudit-pvc2  # pvc2 (jde-cluster3의 pv) 사용
---
# Pod 3
apiVersion: v1
kind: Pod
metadata:
  name: secloudit-pod3
  labels:
    name: app
spec:
  containers:
  - name: app
    image: nginx
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /var/log/nginx    # nginx의 기본 마운트 경로
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:         # nginx의 mountPath를 pv로 마운트 > 영구저장
        claimName: secloudit-pvc3    # pvc3 (jde-cluster4의 pv) 사용
---
# PV, PVC 정적 프로비저닝(NFS)

# NFS용 StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: secloudit-storageclass
  annotations:
    storageclass.kubernetes.io/is-default-class: 'true'
provisioner: kubernetes.io/no-provisioner
reclaimPolicy: Delete
volumeBindingMode: Immediate
---
# NFS PV
apiVersion: v1
kind: PersistentVolume
metadata:
  name: secloudit-pv
spec:
  storageClassName: secloudit-storageclass
  capacity:
    storage: 1Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteMany  # 네트워크 스토리지이므로 여러 노드에서 동시에 읽고 쓰기 가능
  nfs:
    path: "/home/share/nfs" # NFS 서버 내부의 실제 공유 경로
    server: 192.168.9.109
---
# NFS PVC
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: secloudit-pvc
spec:
  storageClassName: secloudit-storageclass
  accessModes:
    - ReadWriteMany  # PV와 마찬가지로 RWX 모드를 요청해야 바인딩됨
  resources:
    requests:
      storage: 1Gi
---
# NFS 테스트 Pod
apiVersion: v1
kind: Pod
metadata:
  name: secloudit-pod
  labels:
    name: app
spec:
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'echo "Platform as a service!" > /mnt/secloudit-nfs.log && sleep 3600']
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /mnt
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:
        claimName: secloudit-pvc
```

| Local Volume                    | NFS                          |
| ------------------------------- | ---------------------------- |
| 특정 Node (`nodeAffinity`)만 접근 가능 | 네트워크를 통해 공유되므로 여러 노드에서 접근 가능 |
| AccessMode: `ReadWriteOnce`     | AccessMode: `ReadWriteMany`  |
```sh
$ kubectl apply -f pod-volume3.yaml
$ kubectl get pod -o wide
```
<img width="2459" height="410" alt="Pasted image 20260108121217" src="https://github.com/user-attachments/assets/31d35d1b-6545-4247-884a-a993bfeb5553" />
<img width="2454" height="306" alt="Pasted image 20260108121316" src="https://github.com/user-attachments/assets/fbd28e25-0608-4cf8-be94-aa0008c8e73c" />

```sh
# Worker Node 1 (jde-cluster2)
$ ssh ubuntu@jde-cluster2 ~/.ssh/id_rsa
$ cat /data/volumes/pv1/secloudit-1.log

# Master Node (jde-cluster1)
$ kubectl exec -it secloudit-pod1 -- sh
$ ls /mnt
# 설정한 mountPath 하위에 secloudit-1.log 파일 확인 가능
```
<img width="1655" height="299" alt="Pasted image 20260108121421" src="https://github.com/user-attachments/assets/c9d36591-e130-4fc2-994e-b15b1fa7aaf9" />

```sh
# Worker Node 2 (jde-cluster3)
$ ssh ubuntu@jde-cluster3 ~/.ssh/id_rsa
$ cat /data/volumes/pv2/secloudit-2.log

# Master Node (jde-cluster1)
$ kubectl exec -it secloudit-pod2 -- sh
$ ls /mnt
# 설정한 mountPath: /mnt 하위 secloudit-2.log 파일 확인 가능능
```
<img width="2004" height="955" alt="Pasted image 20260108121513" src="https://github.com/user-attachments/assets/03762359-9e45-4268-bbe4-538f63d89067" />

```sh
# Worker Node 3 (jde-cluster4)
$ ssh ubuntu@jde-cluster4 ~/.ssh/id_rsa
$ cat /data/volumes/pv3/access.log
$ cat /data/volumes/pv3/error.log
# Pod를 삭제하더라도 해당 경로에 로그 파일이 영구적으로 남아있음

# Master Node (jde-cluster1)
$ kubectl exec -it secloudit-pod3 -- sh
$ ls /var/log/nginx
```
<img width="1661" height="577" alt="Pasted image 20260108121610" src="https://github.com/user-attachments/assets/464cc462-ad3d-4886-b902-c3c174ccc170" />

##### NFS troubleshooting
- https://github.com/K-PaaS/container-platform/blob/master/install-guide/nfs-server-install-guide.md
- `~/values.yaml`
<img width="1855" height="386" alt="Pasted image 20260108123436" src="https://github.com/user-attachments/assets/957c60fb-e95e-454f-98bf-fec923ddb52f" />

- NFS Server IP 오타 $\rightarrow$ `192.168.1.9`로 수정
<img width="2327" height="206" alt="Pasted image 20260108123854" src="https://github.com/user-attachments/assets/00d13904-5bd7-4257-8b75-a1c3e60c8d04" />
<img width="2417" height="447" alt="Pasted image 20260108123906" src="https://github.com/user-attachments/assets/2a0bcbc8-e67c-4ddd-8a20-a3396896f5a6" />

- `helm` 재설치
<img width="2404" height="726" alt="Pasted image 20260108123948" src="https://github.com/user-attachments/assets/ce25cbb3-b77a-443e-8718-342444f5d33c" />
<img width="2183" height="234" alt="Pasted image 20260108124013" src="https://github.com/user-attachments/assets/970c014a-a715-4c55-95f6-1db49655c64b" />

- `jde-ssu-storageclass` 생성
### 5. PersistentVolume: Dynamic Provisioning
- Dynamic Provisioning의 경우 PV를 구성할 필요 없음 (PVC + StorageClass)
	- PVC 배포하면 StorageClass가 알아서 PV 만듦
```yaml
# volume5.yaml

# PVC (Dynamic)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: secloudit-pvc-dynamic
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: jde-ssu-storageclass 
  # storageClass에 지정된 provisioner가 자동으로 PV 생성 + Binding
  resources:
    requests:
      storage: 1Gi
# PV 생성하지 않음
---
# Pod
apiVersion: v1
kind: Pod
metadata:
  name: secloudit-pod-dynamic
  labels:
    name: app
spec:
  containers:
  - name: app
    image: busybox
    command: ['sh', '-c', 'echo "Platform as a service!" > /mnt/secloudit.log && sleep 3600']
    volumeMounts:
      - name: secloudit-local-volume
        mountPath: /mnt
  volumes:
    - name: secloudit-local-volume
      persistentVolumeClaim:
        claimName: secloudit-pvc-dynamic  # 동적 PVC 연결
```
```sh
$ kubectl apply -f volume5.yaml
$ kubectl get pods -o wide

$ ssh ubuntu@jde-cluster5 ~/.ssh/ssu-key.pem
```
<img width="2433" height="271" alt="Pasted image 20260108125241" src="https://github.com/user-attachments/assets/9548f642-19c6-4dae-ba2c-b01042103f38" />
<img width="2386" height="182" alt="Pasted image 20260108125303" src="https://github.com/user-attachments/assets/f6d051e0-667d-4680-876a-90d40f6d50fb" />
<img width="2082" height="767" alt="Pasted image 20260108131028" src="https://github.com/user-attachments/assets/05c7599d-897d-46a1-b56c-e0118c863408" />

- `jde-cluster5` `/home/share/nfs` 공간에 `secloudit-pvc-dynamic-pvc` 자동 생성
